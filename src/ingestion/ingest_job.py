import os
from datetime import datetime, timedelta
from src.ingestion.guardian_api import fetch_guardian_articles
from src.storage.s3_helper import upload_json_to_s3

def run_guardian_ingestion(from_date=None, to_date=None, page_size=50, max_pages=200):
    """
    Fetch Guardian articles and upload as JSON to S3 (bronze/raw zone).
    """
    bucket_name = os.getenv("S3_BUCKET", "the-guardian-data")
    today_str = datetime.utcnow().strftime("%Y-%m-%d")
    timestamp = datetime.utcnow().strftime("%Y%m%dT%H%M%S")
    prefix = f"raw/{today_str}/{timestamp}"

    # ğŸ—“ï¸ Náº¿u khÃ´ng truyá»n, máº·c Ä‘á»‹nh láº¥y 1 ngÃ y gáº§n nháº¥t
    if from_date is None or to_date is None:
        to_date = datetime.utcnow().strftime("%Y-%m-%d")
        from_date = (datetime.utcnow() - timedelta(days=1)).strftime("%Y-%m-%d")

    print(f"ğŸš€ Fetching Guardian articles from {from_date} â†’ {to_date}")

    # ğŸ”¹ Fetch paginated data
    data = fetch_guardian_articles(
        from_date=from_date,
        to_date=to_date,
        page_size=page_size,
        max_pages=max_pages
    )

    if not data:
        print("âš ï¸ No articles fetched â€” skipping upload.")
        return None

    # ğŸ”¹ Upload JSON to S3
    print(f"ğŸ’¾ Uploading raw data to s3://{bucket_name}/{prefix}/")
    s3_key = upload_json_to_s3(data, bucket_name=bucket_name, prefix=prefix)

    print(f"âœ… Ingestion complete! File stored at: s3://{bucket_name}/{s3_key}")
    return s3_key